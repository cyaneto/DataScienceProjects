{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81308b6",
   "metadata": {},
   "source": [
    "## Como os deputados votam: Extração dos dados\n",
    "### Um projeto de aprendizado não supervisado\n",
    "\n",
    "\n",
    "Quando o assunto é política, todo mundo tem um pitaco para dar: seja nos valores que a política deve ter; seja no que cada politico deveria fazer para melhorar nosso país; seja nos reajustes necessários na legislação brasileira. \n",
    "\n",
    "Mas, quando passamos a falar e politica na prática, considerando os projetos de lei, votações na câmara e decretos governamentais ninguém entende muito bem. Se tratando de um país do tamanho do Brasil é entendível que as regras de governo sejam complexas, cheias de processos e burocracias. É parte do sistema democrático.\n",
    "\n",
    "Uma parte importante desse processo são as votações na câmara dos deputados. É la que são aprovados projetos, leis ementas e outras coisas do direito que mudam diretamente ou indiretamente nossa vida enquanto cidadãos. O interessante é que câmara legislativa disponibiliza um volume imenso de dados sobre o que acontece nessas votações, nos permitindo e incentivando a explorar esses dados.\n",
    "\n",
    "Sabendo que a política é atualmente um assunto muito importante para nós brasileiros, mas que não entendemos muito bem o comportamento dos parlamentares nas votações e existem dados que nos permitem explorar um pouco esse comportamento, surgiu a ideia de desenvolver esse projeto: um estudo sobre os dados das votações na câmara dos deputados.\n",
    "\n",
    "Essa é a primeira parte de três. Aqui eu irei extrair os dados da plataforma da câmara legislativa e explicar um pouco como eu fiz para interagir com a plataforma. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf8a9c",
   "metadata": {},
   "source": [
    "### Preparativos\n",
    "\n",
    "Começamos efetuando alguns procedimentos gerais de extração dos dados. No meu caso eu sempre gosto de começar importando as bibliotecas que eu quase sempre uso e definindo os “header” s para a interação com a plataforma.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a7819b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:34:12.964899Z",
     "start_time": "2021-10-07T17:34:08.051672Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import itertools\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time \n",
    "\n",
    "headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e13e5",
   "metadata": {},
   "source": [
    "Em seguida eu decidi definir uma função que basicamente extrai os dados da plataforma conforme a url. Aqui cabe dizer que cada categoria de dado que extrairemos aqui tem um conjunto de especificações e organização diferente, mas a API da câmara legislativa sempre entrega eles num mesmo formato de JSON, onde os dados, estão na chave 'dados'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38695f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:34:12.980903Z",
     "start_time": "2021-10-07T17:34:12.968901Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    response = get(url, headers=headers)\n",
    "    try:\n",
    "        ret = json.loads(response.text)\n",
    "    except ValueError:\n",
    "        ret = {'dados':''}  #para resolver um bug do JSON\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1a196",
   "metadata": {},
   "source": [
    "### Interação com a plataforma\n",
    "\n",
    "Tendo em mãos essa função já podemos testar a extração dos dados de uma url do site da câmara legislativa. Para interagir com essas urls automatizadamente nos precisamos de algumas coisas:\n",
    "\n",
    "\n",
    "- a url em si\n",
    "- como ela varia em parâmetros como datas, numero de página e etc\n",
    "- quais as limitações (máximo de elementos por página, maior intervalo possível)\n",
    "- qual o número máximo de páginas que aquele conjunto de dados gera\n",
    "\n",
    "\n",
    "Todos esses dados estão disponíveis na própria pagina da API da câmara, precisamente nesse link aqui https://dadosabertos.camara.leg.br/swagger/api.html. \n",
    "\n",
    "\n",
    "#### deputados\n",
    "\n",
    "Para pegar a url de um determinado conjunto de dados, como, por exemplo, os dados dos deputados existentes na câmara, basta:\n",
    "\n",
    "- Ir ao link da API\n",
    "- clicar no \"GET\" ao lado do conjunto de dados desejado (no nosso caso deputados)\n",
    "- clicar em \"Try it out\"\n",
    "- mudar os parâmetros caso necessário (coloquei \"pagina\" como 1 apenas para entender onde que isso varia na url)\n",
    "- mudar \"response content type\" para \"application/json\"\n",
    "- clicar em \"execute\"\n",
    "\n",
    "\n",
    "PRRIIIIIINNNTTTTTSSSSSS \n",
    "\n",
    "\n",
    "E assim o site gera uma url (aparece embaixo de \"Request URL\") sendo o que utilizaremos para interagir com os dados por aqui.\n",
    "\n",
    "\n",
    "Para facilitar meu entendimento, dividi as urls em antes e depois do número de página,  e ir variando esse numero para gerar uma url para cada página, e em seguida interagir com cada uma dessas urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b961188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:01:01.524657Z",
     "start_time": "2021-10-01T15:01:01.513659Z"
    }
   },
   "outputs": [],
   "source": [
    "url_1='https://dadosabertos.camara.leg.br/api/v2/deputados?pagina='\n",
    "url_2='&itens=60&ordem=ASC&ordenarPor=nome'\n",
    "urls=[]\n",
    "for p in range(1, 10):\n",
    "    urls.append(url_1+str(p)+url_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d8cd6",
   "metadata": {},
   "source": [
    "A extração dos dados é feita como mostra o código abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cd71b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T18:17:18.909910Z",
     "start_time": "2021-09-29T18:17:13.927507Z"
    }
   },
   "outputs": [],
   "source": [
    "cols=['id', 'nome', 'siglaUf', 'siglaPartido', 'idLegislatura']\n",
    "deputados=pd.DataFrame(columns=cols)\n",
    "for url in urls:\n",
    "    data =get_data(url)\n",
    "    for d in data['dados']:\n",
    "        data_point={}\n",
    "        for c in cols:\n",
    "            data_point[c]=d[c]\n",
    "        deputados=deputados.append(data_point, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af293453",
   "metadata": {},
   "source": [
    "Aqui separei o nome das colunas que quero em uma lista (cols) e ir puxando do dos dados cada um desses elementos, gerando uma linha da nossa futura tabela de dados. Essa linha é \"apendada\" no final da tabela, e no final desse loop tenho o dataset dos deputados. Por fim eu salvei esses dados no meu PC. Isso será algo muito importante ao longo do projeto, pois os dados que estamos extraindo tomam uma quantidade alta de tempo e não podem ser armazenados só na memória RAM tendo o risco de perde-los sob qualquer imprevisto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897cde4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T18:09:14.458094Z",
     "start_time": "2021-09-30T18:09:14.433093Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'E:\\prog\\PYMLAIDS\\Camara dos deputados\\data'\n",
    "\n",
    "output_file = os.path.join(path,'deputados.csv')\n",
    "deputados.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afcd772",
   "metadata": {},
   "source": [
    "Feito isso agora generalizaremos o 'for' que utilizamos para interagir em cada página usando uma função que faz a mesma coisa. Ela toma como parâmetro as 2 partes da url, as colunas e o número de páginas máximo, e extrai os dados da mesma forma que na função anterior. Nessa função adicionei um tqdm, sendo basicamente uma função que cria uma barra de progresso para o interador(nesse caso as url). Assim tenho uma noção de como está o andamento do processamento dos dados e se tiver algum bug ou erro no meio do caminho eu consigo ver qual url que está dando problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b7e33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T18:17:21.989587Z",
     "start_time": "2021-09-29T18:17:21.968585Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_pages(url_1, url_2, cols, n_paginas=2):\n",
    "    urls=[]\n",
    "    for p in range(1,n_paginas+1):\n",
    "        urls.append(url_1+str(p)+url_2)\n",
    "    ret= pd.DataFrame(columns=cols)\n",
    "    for url in tqdm(urls, leave=False):\n",
    "        data =get_data(url)\n",
    "        for d in data['dados']:\n",
    "            data_point={}\n",
    "            for c in cols:\n",
    "                data_point[c]=d[c]\n",
    "            ret=ret.append(data_point, ignore_index=True)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8f1c8",
   "metadata": {},
   "source": [
    "#### votações\n",
    "\n",
    "O próximo conjunto de dados que extrairemos são as votações. O que queremos é basicamente uma tabela com o identificador de cada votação, a data, o órgão que realizou e se foi aprovada ou não. O esquema é o mesmo do conjunto de dados anterior, exceto que agora precisamos especificar a data de início e de término do conjunto de dados. Primeiro testo com dados dos 2 primeiros meses de 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39610cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:21:11.378970Z",
     "start_time": "2021-10-01T15:19:06.249479Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_votacoes=['id', 'data', 'siglaOrgao', 'aprovacao']\n",
    "url_1_votacoes='https://dadosabertos.camara.leg.br/api/v2/votacoes?dataInicio=2020-01-01&dataFim=2020-02-28&pagina='\n",
    "url_2_votacoes= '&ordem=DESC&ordenarPor=dataHoraRegistro'\n",
    "n_pag_votacoes=10\n",
    "votacoes=get_data_pages(url_1_votacoes, url_2_votacoes, cols_votacoes, n_pag_votacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501a559",
   "metadata": {},
   "source": [
    "Sabendo que a extração dos dados das votações esta funcionando bem hora de generalizar para vários intervalos de tempo entre janeiro de 2019 e hoje. Os intervalos de datas não podem ser grandes demais, pois quando isso acontece o site da câmara retorna erro por demorar demais para processar esses dados. Os intervalos também não podem ser muito pequenos, porque a extração de cada página da câmara dos deputados ficaria muito lenta e o código demoraria horrores para rodar. Usei 60 dias nesse caso como intervalo, escolhido de forma bem arbitraria.\n",
    "\n",
    "A API da câmara dos deputados também tem uma peculiaridade relacionada às datas: ela não consegue retornar dados de dois anos diferentes na mesma url. Isso é facilmente resolvível com alguns 'if' s no meio do for. O site também não aceita pedidos com datas além de hoje, por isso é necessário limitar nosso intervalo em relação a hoje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bebe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:40:09.565710Z",
     "start_time": "2021-10-01T15:40:09.542712Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "date_0= date(2019, 1, 1)\n",
    "\n",
    "date_i= date_0\n",
    "date_f= date_0+timedelta(days = 60)\n",
    "\n",
    "dates=[]\n",
    "for i in range (1000):\n",
    "    if date_f> date.today():\n",
    "        dates.append([date_i, date.today()])\n",
    "        break\n",
    "    if date_f.year != date_i.year:\n",
    "        dates.append([date_i, date(date_i.year,12,31)])\n",
    "        date_i=date(date_f.year,1,1)\n",
    "        date_f=date_i+timedelta(days = 61)\n",
    "    else:\n",
    "        dates.append([date_i, date_f])\n",
    "        date_i=date_f+timedelta(days = 1)\n",
    "        date_f=date_f+timedelta(days = 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390dd63",
   "metadata": {},
   "source": [
    "O bloco das datas fica do lado esquerdo do bloco do número de página, por isso é mais fácil de implementa-lo na url_1. Eu preferi criar uma lista com todas as primeiras partes da url das votações e em seguida interagir com elas em um for, assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1323d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T11:46:40.265087Z",
     "start_time": "2021-10-03T11:46:40.063072Z"
    }
   },
   "outputs": [],
   "source": [
    "url_1s=[]\n",
    "for d in dates:\n",
    "    url_1s.append('https://dadosabertos.camara.leg.br/api/v2/votacoes?dataInicio='+str(d[0])+'&dataFim='+str(d[1])+'&pagina=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f71b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T11:46:40.377094Z",
     "start_time": "2021-10-03T11:46:40.362094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_votacoes=['id', 'data', 'siglaOrgao', 'aprovacao']\n",
    "\n",
    "url_2_votacoes= '&ordem=DESC&ordenarPor=dataHoraRegistro'\n",
    "n_pag_votacoes=10\n",
    "\n",
    "votacoes=pd.DataFrame(columns=cols_votacoes)\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "inputs = tqdm(url_1s)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processed_list = Parallel(n_jobs=num_cores)(delayed(get_data_pages)(i,url_2_votacoes, cols_votacoes, n_pag_votacoes) for i in inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ed34a",
   "metadata": {},
   "source": [
    "Aqui eu preferi ao invés de implementar um simples for utilizar um pouco de processamento paralelo, pois essa extração estava prometendo demorar mais de horas para rodar, e se no meio disso a internet caísse eu perderia todo o progresso. No processamento paralelo isso é contornado um pouco, pois o código é executado mais rapidamente.\n",
    "\n",
    "Da mesma forma que no conjunto anterior eu decidi salvar para não perder as horas que esse código demorou para rodar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6552e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T11:50:39.822496Z",
     "start_time": "2021-10-03T11:50:39.799509Z"
    }
   },
   "outputs": [],
   "source": [
    "votacoes=pd.concat(processed_list)\n",
    "output_file = os.path.join(path,'votacoes.csv')\n",
    "votacoes.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d2818",
   "metadata": {},
   "source": [
    "#### Votos\n",
    "\n",
    "Agora é só extrair os votos de cada deputado nessas votações. A interação com a url é bem simples, é basicamente mudar o 'id' da votação no modelo e extrair o que está na chave 'dados'  do objeto JSON. Nem todas as votações têm os dados dos votos de cada deputado, mas o código contorna esse problema bem-visto que o site simplesmente retorna uma string vazio para a chae 'dados' nesses casos. Nesse caso eu preferi não fazer de forma paralela, pois diferente do caso anterior as paginas interagem muito rápido e paralelizar o código não é muito uma vantagem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db163cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-29T20:27:00.910800Z",
     "start_time": "2021-09-29T18:34:24.613865Z"
    }
   },
   "outputs": [],
   "source": [
    "votos={}\n",
    "\n",
    "url_1_votos='https://dadosabertos.camara.leg.br/api/v2/votacoes/'\n",
    "url_2_votos='/votos' \n",
    "urls=[]\n",
    "for ID in tqdm( votacoes['id']):\n",
    "    url =url_1_votos+str(ID)+url_2_votos\n",
    "    data =get_data(url)\n",
    "    if len(data['dados'])>0:\n",
    "        votos[ID]={d[\"deputado_\"]['id']:d[\"tipoVoto\"] for d in data['dados']}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e372e9d",
   "metadata": {},
   "source": [
    "Aqui cada linha representa um deputado (o 'index' do dataset é o id do deputado) e cada coluna representa uma votação. Mais uma vez salvamos os dados em um arquivo CSV para honrar as horas de processamento que gastei com esse código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf707708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T14:41:27.752375Z",
     "start_time": "2021-09-30T14:41:27.424277Z"
    }
   },
   "outputs": [],
   "source": [
    "votos=pd.DataFrame(votos)\n",
    "output_file = os.path.join(path,'votos.csv')\n",
    "votos.to_csv(output_file, index=True, index_label='cod_deputado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f6987",
   "metadata": {},
   "source": [
    "#### Orientações\n",
    "\n",
    "\n",
    "Por fim, eu decidi extrair também os dados sobre as orientações dos partidos e blocos a respeito das votações. A ideia aqui é possivelmente usar esses dados para entender o quanto os deputados estão alinhados com os seus partidos e talvez até imputar os votos dos deputados que estiverem faltando com essas orientações do partido. É importante dizer que as orientações podem ser identificadas por 'B' (de um bloco) ou 'P' (de um partido), e para ter um dataset mais conciso escolhi usar como index uma combinação desses fatores. Então, as orientações de um partido 'PPT' teriam como index 'PPT'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9bf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T12:03:50.081604Z",
     "start_time": "2021-10-03T12:03:50.057616Z"
    }
   },
   "outputs": [],
   "source": [
    "orientacoes = {}\n",
    "url_1_orientacoes = 'https://dadosabertos.camara.leg.br/api/v2/votacoes/'\n",
    "url_2_orientacoes = '/orientacoes'\n",
    "urls = []\n",
    "for ID in tqdm(votos.columns):\n",
    "    url = url_1_orientacoes+str(ID)+url_2_orientacoes\n",
    "    data = get_data(url)\n",
    "    if len(data['dados']) > 0:\n",
    "        if d[\"codTipoLideranca\"] == None: \n",
    "            orientacoes[ID] = {'N'+str(\n",
    "                d['siglaPartidoBloco']): d[\"orientacaoVoto\"] for d in data['dados']}\n",
    "        else:\n",
    "            orientacoes[ID] = {str(d[\"codTipoLideranca\"])+str(\n",
    "                d['siglaPartidoBloco']): d[\"orientacaoVoto\"] for d in data['dados']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91367eb",
   "metadata": {},
   "source": [
    "Salvando mais uma vez os dados e assim terminando a extração os dados:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7654d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T12:09:24.200887Z",
     "start_time": "2021-10-03T12:09:24.188898Z"
    }
   },
   "outputs": [],
   "source": [
    "orientacoes=pd.DataFrame(orientacoes)\n",
    "output_file = os.path.join(path,'orientacoes.csv')\n",
    "orientacoes.to_csv(output_file, index=True, index_label='cod_partido')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fe97b",
   "metadata": {},
   "source": [
    "### Proximos passos\n",
    "\n",
    "Apos extrair esses dados, eu os limpei, filtrei e combinei nesse artigo aqui: LINK_1. Com esses dados tratados eu re-classifiquei os deputados com base em seu comportamento nas votações, nesse artigo aqui: LINK_2."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
